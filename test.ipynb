{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have shape (1, 10) but got array with shape (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 142>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnest_asyncio\u001b[39;00m\n\u001b[0;32m    145\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_dqn_training()\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mrun_dqn_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m dqn_agent\u001b[38;5;241m.\u001b[39mcompile(Adam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Training with logging\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m history \u001b[38;5;241m=\u001b[39m dqn_agent\u001b[38;5;241m.\u001b[39mfit(train_player_env, nb_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    120\u001b[0m train_player_env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mselect_action(q_values\u001b[38;5;241m=\u001b[39mq_values)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_q_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_batch_q_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_batch_q_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mlen\u001b[39m(state_batch), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:1304\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith tf.distribute.Strategy.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m     )\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;66;03m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m inputs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_user_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_tensors_from_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;66;03m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;66;03m# context at this point.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_eagerly \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2649\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(_is_symbolic_tensor(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m all_inputs)\n\u001b[0;32m   2646\u001b[0m ):\n\u001b[0;32m   2647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], [], \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standardize_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdict_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdict_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2690\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;66;03m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset)):\n\u001b[0;32m   2689\u001b[0m     \u001b[38;5;66;03m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2690\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils_v1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_input_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_input_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeed_input_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2698\u001b[0m \u001b[38;5;66;03m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[38;5;66;03m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[38;5;66;03m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[38;5;66;03m# standardization code.\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:733\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m dim, ref_dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_shape, shape):\n\u001b[0;32m    728\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    729\u001b[0m                     ref_dim \u001b[38;5;241m!=\u001b[39m dim\n\u001b[0;32m    730\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m ref_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    731\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    732\u001b[0m                 ):\n\u001b[1;32m--> 733\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    734\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when checking \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m+\u001b[39m exception_prefix\n\u001b[0;32m    736\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                         \u001b[38;5;241m+\u001b[39m names[i]\n\u001b[0;32m    738\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to have shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(shape)\n\u001b[0;32m    740\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got array with shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    741\u001b[0m                         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(data_shape)\n\u001b[0;32m    742\u001b[0m                     )\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have shape (1, 10) but got array with shape (1, 2)"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gymnasium.spaces import Box, Space\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import EpsGreedyQPolicy, LinearAnnealedPolicy\n",
    "from tabulate import tabulate\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "from poke_env.player import (\n",
    "    Gen8EnvSinglePlayer,\n",
    "    MaxBasePowerPlayer,\n",
    "    ObsType,\n",
    "    RandomPlayer,\n",
    "    SimpleHeuristicsPlayer,\n",
    "    background_cross_evaluate,\n",
    "    background_evaluate_player,\n",
    ")\n",
    "from poke_env.data import GenData\n",
    "\n",
    "type_chart = GenData(9).type_chart\n",
    "\n",
    "class DQNPlayer(Gen8EnvSinglePlayer):\n",
    "    def calc_reward(self, last_battle, current_battle) -> float:\n",
    "        # Add reward for dealing damage and penalty for fainted Pokémon\n",
    "        damage_dealt = (last_battle.opponent_active_pokemon.current_hp - \n",
    "                        current_battle.opponent_active_pokemon.current_hp)\n",
    "        reward = self.reward_computing_helper(\n",
    "            current_battle,\n",
    "            fainted_value=2.0,\n",
    "            hp_value=1.0,\n",
    "            victory_value=30.0,\n",
    "        )\n",
    "        # Reward for damage dealt\n",
    "        reward += damage_dealt * 0.5\n",
    "        return reward\n",
    "\n",
    "    def embed_battle(self, battle: AbstractBattle) -> ObsType:\n",
    "        # Embed battle with action masking for unavailable moves\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = move.base_power / 100\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=type_chart\n",
    "                )\n",
    "\n",
    "        fainted_mon_team = len([mon for mon in battle.team.values() if mon.fainted]) / 6\n",
    "        fainted_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if mon.fainted]) / 6\n",
    "        )\n",
    "\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_base_power,\n",
    "                moves_dmg_multiplier,\n",
    "                [fainted_mon_team, fainted_mon_opponent],\n",
    "            ]\n",
    "        )\n",
    "        return np.float32(final_vector)\n",
    "\n",
    "    def describe_embedding(self) -> Space:\n",
    "        low = [-1] * 4 + [0] * 4 + [0, 0]\n",
    "        high = [3] * 4 + [4] * 4 + [1, 1]\n",
    "        return Box(np.array(low, dtype=np.float32), np.array(high, dtype=np.float32), dtype=np.float32)\n",
    "\n",
    "async def run_dqn_training():\n",
    "    train_opponent = RandomPlayer(battle_format=\"gen8randombattle\")\n",
    "    train_player_env = DQNPlayer(\n",
    "        battle_format=\"gen8randombattle\", opponent=train_opponent, start_challenging=True\n",
    "    )\n",
    "    eval_opponent = RandomPlayer(battle_format=\"gen8randombattle\")\n",
    "    eval_player_env = DQNPlayer(\n",
    "        battle_format=\"gen8randombattle\", opponent=eval_opponent, start_challenging=True\n",
    "    )\n",
    "\n",
    "    n_actions = train_player_env.action_space.n\n",
    "    input_shape = (1,) + train_player_env.observation_space.shape\n",
    "\n",
    "    dqn_model = Sequential([\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(128, activation=\"elu\"),\n",
    "        Dense(64, activation=\"elu\"),\n",
    "        Dense(n_actions, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn_policy = LinearAnnealedPolicy(\n",
    "        EpsGreedyQPolicy(),\n",
    "        attr=\"eps\",\n",
    "        value_max=1.0,\n",
    "        value_min=0.1,\n",
    "        value_test=0.05,\n",
    "        nb_steps=50000,\n",
    "    )\n",
    "\n",
    "    dqn_agent = DQNAgent(\n",
    "        model=dqn_model,\n",
    "        nb_actions=n_actions,\n",
    "        policy=dqn_policy,\n",
    "        memory=memory,\n",
    "        nb_steps_warmup=1000,\n",
    "        gamma=0.9,\n",
    "        target_model_update=1000,\n",
    "        enable_double_dqn=True,\n",
    "    )\n",
    "    dqn_agent.compile(Adam(learning_rate=0.001), metrics=[\"mae\"])\n",
    "\n",
    "    # Training with logging\n",
    "    history = dqn_agent.fit(train_player_env, nb_steps=50000, visualize=False, verbose=2)\n",
    "    train_player_env.close()\n",
    "\n",
    "    # Save the model\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.makedirs(\"models\")\n",
    "    dqn_agent.model.save(\"models/dqn_pokemon_model.h5\")\n",
    "\n",
    "    # Plot training rewards\n",
    "    plt.plot(history.history[\"episode_reward\"])\n",
    "    plt.title(\"Training Rewards\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"Evaluating against random player...\")\n",
    "    dqn_agent.test(eval_player_env, nb_episodes=100, visualize=False)\n",
    "    print(\n",
    "        f\"Victories: {eval_player_env.n_won_battles} / {eval_player_env.n_finished_battles}\"\n",
    "    )\n",
    "    eval_player_env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio\n",
    "\n",
    "    nest_asyncio.apply()\n",
    "    await run_dqn_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 165      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.23    |\n",
      "|    explained_variance | 0.246    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.51     |\n",
      "|    value_loss         | 1.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 188      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    value_loss         | 0.321    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 202      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0.018    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 6.7      |\n",
      "|    value_loss         | 5.69     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.1     |\n",
      "|    explained_variance | -0.283   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.29    |\n",
      "|    value_loss         | 0.132    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 211       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.856     |\n",
      "|    value_loss         | 0.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 214      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | -2.23    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0257   |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.12    |\n",
      "|    explained_variance | 0.0241   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    value_loss         | 166      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | -0.00782 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0374  |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | -0.644   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    value_loss         | 0.182    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.15    |\n",
      "|    explained_variance | -0.0316  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 7.59     |\n",
      "|    value_loss         | 7.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.35    |\n",
      "|    explained_variance | -4.78    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 4.19     |\n",
      "|    value_loss         | 6.53     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | -0.0231  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.308    |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 228      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.03    |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.284    |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 227      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | -0.0197  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.466   |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.66    |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 37.2     |\n",
      "|    value_loss         | 489      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 229      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0.0207   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    value_loss         | 8.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.75    |\n",
      "|    explained_variance | 0.138    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.43     |\n",
      "|    value_loss         | 3.92     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.58    |\n",
      "|    explained_variance | 0.000231 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 3.2      |\n",
      "|    value_loss         | 7.88     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | 0.124    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -1.12    |\n",
      "|    value_loss         | 0.658    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.82    |\n",
      "|    explained_variance | 0.196    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 2.49     |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.053    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.251    |\n",
      "|    value_loss         | 2.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.6     |\n",
      "|    explained_variance | 0.0859   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 2.61     |\n",
      "|    value_loss         | 4.56     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.47    |\n",
      "|    explained_variance | -0.05    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.372    |\n",
      "|    value_loss         | 0.0364   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.94    |\n",
      "|    explained_variance | -0.0296  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.128   |\n",
      "|    value_loss         | 0.0178   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 0.0224   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.422    |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.88    |\n",
      "|    explained_variance | 0.0361   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 1.91     |\n",
      "|    value_loss         | 8.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.0517   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.57     |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | 0.0148   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.38     |\n",
      "|    value_loss         | 6.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | -0.479   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.199   |\n",
      "|    value_loss         | 0.175    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.621   |\n",
      "|    value_loss         | 0.248    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.931   |\n",
      "|    explained_variance | 0.00276  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 5.04     |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.62    |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 7.19     |\n",
      "|    value_loss         | 8.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.53    |\n",
      "|    explained_variance | -0.0165  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 7.64     |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.59    |\n",
      "|    explained_variance | 0.0071   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 4.46     |\n",
      "|    value_loss         | 25.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 232       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46     |\n",
      "|    explained_variance | -0.000692 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 1.66      |\n",
      "|    value_loss         | 2.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -3.56    |\n",
      "|    value_loss         | 8.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | 0.0128   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 1.66     |\n",
      "|    value_loss         | 6.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | -0.015   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0693  |\n",
      "|    value_loss         | 0.00461  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.0306   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.612   |\n",
      "|    value_loss         | 0.362    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.00299  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.141    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.907    |\n",
      "|    value_loss         | 0.728    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 90       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.41    |\n",
      "|    explained_variance | -0.0382  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.0105   |\n",
      "|    value_loss         | 0.0318   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.0221   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.3      |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | -0.00434 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 3.18     |\n",
      "|    value_loss         | 3.3      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -1.48    |\n",
      "|    value_loss         | 1.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.983   |\n",
      "|    explained_variance | 0.0071   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.515   |\n",
      "|    value_loss         | 0.234    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 23500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | -0.0876  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.699   |\n",
      "|    value_loss         | 0.304    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.63    |\n",
      "|    explained_variance | -0.288   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.184   |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 104      |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.553   |\n",
      "|    explained_variance | -0.0103  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.61     |\n",
      "|    value_loss         | 82.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.03    |\n",
      "|    explained_variance | -0.0272  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -1.94    |\n",
      "|    value_loss         | 1.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.932   |\n",
      "|    explained_variance | -0.0452  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 3.81     |\n",
      "|    value_loss         | 55.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.872   |\n",
      "|    explained_variance | 0.00908  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 3.51     |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.527   |\n",
      "|    explained_variance | -1       |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.0985  |\n",
      "|    value_loss         | 0.782    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 116      |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.264   |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.116   |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 118      |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.451   |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.0463   |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.447   |\n",
      "|    explained_variance | 0.024    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    value_loss         | 37.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | -0.00074 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.366   |\n",
      "|    value_loss         | 0.367    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.382   |\n",
      "|    explained_variance | 0.00274  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    value_loss         | 7.19     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.709   |\n",
      "|    explained_variance | 0.00216  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | -0.771   |\n",
      "|    value_loss         | 0.912    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.28    |\n",
      "|    explained_variance | 0.0075   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.335    |\n",
      "|    value_loss         | 28.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.0665   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.421    |\n",
      "|    value_loss         | 2.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.624   |\n",
      "|    explained_variance | -0.00931 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.667   |\n",
      "|    value_loss         | 4.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.839   |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.222   |\n",
      "|    value_loss         | 1.42     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.648    |\n",
      "|    explained_variance | -0.000636 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 2.08      |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | -0.568   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.0557   |\n",
      "|    value_loss         | 0.783    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 141      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.526   |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -0.0911  |\n",
      "|    value_loss         | 0.883    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | -0.029   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -0.308   |\n",
      "|    value_loss         | 4.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.013    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 4.91     |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 148      |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.241   |\n",
      "|    explained_variance | -0.0227  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.258    |\n",
      "|    value_loss         | 26.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.908   |\n",
      "|    explained_variance | 0.0319   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | -1.81    |\n",
      "|    value_loss         | 4.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 152      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.578   |\n",
      "|    explained_variance | 0.219    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.0654  |\n",
      "|    value_loss         | 4.18     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 154      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.755   |\n",
      "|    explained_variance | 0.0306   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.341    |\n",
      "|    value_loss         | 2.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.918   |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -1.43    |\n",
      "|    value_loss         | 4.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 158      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.202   |\n",
      "|    explained_variance | -0.00579 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.0958   |\n",
      "|    value_loss         | 2.5      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.84    |\n",
      "|    explained_variance | 0.262    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -2.15    |\n",
      "|    value_loss         | 8.47     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.531   |\n",
      "|    explained_variance | -1.39    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    value_loss         | 0.0489   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 164      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0944  |\n",
      "|    explained_variance | 0.553    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.212    |\n",
      "|    value_loss         | 0.0713   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.613   |\n",
      "|    explained_variance | -0.0195  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 0.19     |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.716   |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -0.334   |\n",
      "|    value_loss         | 0.317    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.39    |\n",
      "|    explained_variance | 0.166    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -0.0918  |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.193   |\n",
      "|    explained_variance | -0.023   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -0.0116  |\n",
      "|    value_loss         | 0.494    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.591   |\n",
      "|    explained_variance | 0.318    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.00362  |\n",
      "|    value_loss         | 7.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.407   |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.269   |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0907  |\n",
      "|    explained_variance | 0.252    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.0123  |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 181      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.443   |\n",
      "|    explained_variance | 0.391    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.765   |\n",
      "|    value_loss         | 0.93     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 183      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0643  |\n",
      "|    explained_variance | 0.0672   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.00553 |\n",
      "|    value_loss         | 2.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 186      |\n",
      "|    total_timesteps    | 43500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.512   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    value_loss         | 0.387    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.368   |\n",
      "|    explained_variance | -0.164   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -0.857   |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0706  |\n",
      "|    explained_variance | 0.0716   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.0279   |\n",
      "|    value_loss         | 12.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.44    |\n",
      "|    explained_variance | -0.0231  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | -0.191   |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | -0.0871  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 5.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.524   |\n",
      "|    explained_variance | 0.0508   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -1.05    |\n",
      "|    value_loss         | 7.6      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.21    |\n",
      "|    explained_variance | 0.0876   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.13    |\n",
      "|    value_loss         | 0.257    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.1     |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 0.0504   |\n",
      "|    value_loss         | 11.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.615   |\n",
      "|    explained_variance | 0.509    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.108    |\n",
      "|    value_loss         | 0.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.402   |\n",
      "|    explained_variance | -0.494   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -1.17    |\n",
      "|    value_loss         | 4.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 207      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.381   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | -0.125   |\n",
      "|    value_loss         | 3.27     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.384   |\n",
      "|    explained_variance | 0.179    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 0.439    |\n",
      "|    value_loss         | 49.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 211      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.203    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.0329   |\n",
      "|    value_loss         | 0.874    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.96    |\n",
      "|    explained_variance | 0.2      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    value_loss         | 0.608    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 10100    |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 50500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.22    |\n",
      "|    explained_variance | 0.0679   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10099    |\n",
      "|    policy_loss        | 0.0683   |\n",
      "|    value_loss         | 6.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.248   |\n",
      "|    explained_variance | -3.67    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -0.0891  |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 219      |\n",
      "|    total_timesteps    | 51500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.637   |\n",
      "|    explained_variance | 0.399    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | -0.112   |\n",
      "|    value_loss         | 0.361    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.519   |\n",
      "|    explained_variance | 0.0923   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.574   |\n",
      "|    value_loss         | 6.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10500    |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 52500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.358   |\n",
      "|    explained_variance | 0.066    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10499    |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    value_loss         | 5.51     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 226      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.908   |\n",
      "|    explained_variance | -0.00452 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -10      |\n",
      "|    value_loss         | 1.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10700    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 53500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.25     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10699    |\n",
      "|    policy_loss        | -1.77    |\n",
      "|    value_loss         | 6.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.583   |\n",
      "|    explained_variance | -0.0928  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.407   |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 234      |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 54500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0717  |\n",
      "|    explained_variance | 0.33     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | 0.0113   |\n",
      "|    value_loss         | 1.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11000    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | -15.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10999    |\n",
      "|    policy_loss        | 0.357    |\n",
      "|    value_loss         | 0.264    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 238      |\n",
      "|    total_timesteps    | 55500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.348    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.0128  |\n",
      "|    value_loss         | 3.9      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 240      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.78    |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    value_loss         | 2.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 56500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.953   |\n",
      "|    explained_variance | 0.0226   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | 0.468    |\n",
      "|    value_loss         | 0.94     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 244      |\n",
      "|    total_timesteps    | 57000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | -0.234   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.432   |\n",
      "|    value_loss         | 6.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 246      |\n",
      "|    total_timesteps    | 57500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.486   |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | -0.496   |\n",
      "|    value_loss         | 2.52     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11600    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.744   |\n",
      "|    explained_variance | 0.0289   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11599    |\n",
      "|    policy_loss        | -2.18    |\n",
      "|    value_loss         | 7.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11700    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 58500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.468   |\n",
      "|    explained_variance | 0.081    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11699    |\n",
      "|    policy_loss        | 0.276    |\n",
      "|    value_loss         | 6.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 252      |\n",
      "|    total_timesteps    | 59000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.797   |\n",
      "|    explained_variance | 0.0916   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.618   |\n",
      "|    value_loss         | 0.844    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 254      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.838   |\n",
      "|    explained_variance | 0.72     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.851    |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12000    |\n",
      "|    time_elapsed       | 257      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.241   |\n",
      "|    explained_variance | 0.502    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.035    |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 60500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.31    |\n",
      "|    explained_variance | 0.452    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -0.563   |\n",
      "|    value_loss         | 1.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 261      |\n",
      "|    total_timesteps    | 61000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.22    |\n",
      "|    explained_variance | 0.26     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.0449   |\n",
      "|    value_loss         | 0.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12300    |\n",
      "|    time_elapsed       | 263      |\n",
      "|    total_timesteps    | 61500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.387   |\n",
      "|    explained_variance | 0.334    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12299    |\n",
      "|    policy_loss        | 1.44     |\n",
      "|    value_loss         | 5.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12400    |\n",
      "|    time_elapsed       | 265      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.424   |\n",
      "|    explained_variance | 0.499    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12399    |\n",
      "|    policy_loss        | -0.086   |\n",
      "|    value_loss         | 2.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 267      |\n",
      "|    total_timesteps    | 62500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.64    |\n",
      "|    explained_variance | 0.187    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 0.352    |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 63000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.459   |\n",
      "|    explained_variance | -1.4     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -1.01    |\n",
      "|    value_loss         | 2.78     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.157   |\n",
      "|    explained_variance | 0.19     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | 0.00648  |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12800    |\n",
      "|    time_elapsed       | 273      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.435   |\n",
      "|    explained_variance | 0.0908   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12799    |\n",
      "|    policy_loss        | 0.256    |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 64500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.595   |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | 0.926    |\n",
      "|    value_loss         | 3.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 278      |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.219   |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | 0.0292   |\n",
      "|    value_loss         | 1.41     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 65500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.399   |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | -0.159   |\n",
      "|    value_loss         | 2.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.131   |\n",
      "|    explained_variance | 0.284    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0.00639 |\n",
      "|    value_loss         | 0.868    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 284      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.207   |\n",
      "|    explained_variance | -2.55    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -0.0065  |\n",
      "|    value_loss         | 0.0278   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 286      |\n",
      "|    total_timesteps    | 67000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.316   |\n",
      "|    explained_variance | 0.231    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -0.257   |\n",
      "|    value_loss         | 0.622    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 67500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 0.133    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    value_loss         | 5.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 290      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.35    |\n",
      "|    explained_variance | -0.00457 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | 1.32     |\n",
      "|    value_loss         | 19.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 233      |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 292      |\n",
      "|    total_timesteps    | 68500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.217   |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | 1.75     |\n",
      "|    value_loss         | 0.922    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 69000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.132   |\n",
      "|    explained_variance | -0.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | 0.00161  |\n",
      "|    value_loss         | 0.967    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 298      |\n",
      "|    total_timesteps    | 69500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0574  |\n",
      "|    explained_variance | 0.499    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | 0.00548  |\n",
      "|    value_loss         | 0.849    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14000    |\n",
      "|    time_elapsed       | 300      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0833  |\n",
      "|    explained_variance | 0.335    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.0154  |\n",
      "|    value_loss         | 3.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 303      |\n",
      "|    total_timesteps    | 70500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.313   |\n",
      "|    explained_variance | 0.497    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -1.07    |\n",
      "|    value_loss         | 7.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 71000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.251   |\n",
      "|    explained_variance | 0.294    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -0.0181  |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 307      |\n",
      "|    total_timesteps    | 71500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.45    |\n",
      "|    explained_variance | 0.299    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | 3.71     |\n",
      "|    value_loss         | 4        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.381   |\n",
      "|    explained_variance | -4.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    value_loss         | 4.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 312      |\n",
      "|    total_timesteps    | 72500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.366   |\n",
      "|    explained_variance | 0.154    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 0.679    |\n",
      "|    value_loss         | 12.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 73000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.42    |\n",
      "|    explained_variance | 0.287    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 4.43     |\n",
      "|    value_loss         | 5.08     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 14700    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 73500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.409   |\n",
      "|    explained_variance | 0.548    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14699    |\n",
      "|    policy_loss        | 0.574    |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.61    |\n",
      "|    explained_variance | 0.34     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 1.64     |\n",
      "|    value_loss         | 10.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 321      |\n",
      "|    total_timesteps    | 74500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.426   |\n",
      "|    explained_variance | 0.255    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | 0.39     |\n",
      "|    value_loss         | 4.16     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15000    |\n",
      "|    time_elapsed       | 323      |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.204   |\n",
      "|    explained_variance | 0.284    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14999    |\n",
      "|    policy_loss        | -0.0242  |\n",
      "|    value_loss         | 0.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 325      |\n",
      "|    total_timesteps    | 75500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.14    |\n",
      "|    explained_variance | -0.836   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | 0.0268   |\n",
      "|    value_loss         | 0.306    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.245    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.427   |\n",
      "|    value_loss         | 0.703    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 330      |\n",
      "|    total_timesteps    | 76500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.253   |\n",
      "|    explained_variance | 0.453    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 1.95     |\n",
      "|    value_loss         | 0.575    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15400    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 77000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.817   |\n",
      "|    explained_variance | 0.387    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15399    |\n",
      "|    policy_loss        | -0.454   |\n",
      "|    value_loss         | 3.01     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 334      |\n",
      "|    total_timesteps    | 77500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.666   |\n",
      "|    explained_variance | -0.121   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | 0.179    |\n",
      "|    value_loss         | 0.788    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 336      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.552   |\n",
      "|    explained_variance | -0.258   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0.194   |\n",
      "|    value_loss         | 1.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 338      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.0854   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 5.85     |\n",
      "|    value_loss         | 27.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 79000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.909   |\n",
      "|    explained_variance | 0.221    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | 0.0938   |\n",
      "|    value_loss         | 1.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 79500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.338   |\n",
      "|    explained_variance | 0.0487   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 10.3     |\n",
      "|    value_loss         | 12.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16000    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.518   |\n",
      "|    explained_variance | 0.195    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.321   |\n",
      "|    value_loss         | 1.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 347      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.836   |\n",
      "|    explained_variance | 0.46     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | -2.9     |\n",
      "|    value_loss         | 2.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 349      |\n",
      "|    total_timesteps    | 81000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.464   |\n",
      "|    explained_variance | 0.267    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0.592   |\n",
      "|    value_loss         | 0.856    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 351      |\n",
      "|    total_timesteps    | 81500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.709   |\n",
      "|    explained_variance | 0.256    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | 1.8      |\n",
      "|    value_loss         | 4.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16400    |\n",
      "|    time_elapsed       | 353      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16399    |\n",
      "|    policy_loss        | 5.68     |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 82500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | -0.21    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 0.402    |\n",
      "|    value_loss         | 0.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 357      |\n",
      "|    total_timesteps    | 83000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.34    |\n",
      "|    explained_variance | -0.491   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.0439   |\n",
      "|    value_loss         | 1.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 359      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.416   |\n",
      "|    explained_variance | -0.217   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | 0.345    |\n",
      "|    value_loss         | 3.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 361      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0868  |\n",
      "|    explained_variance | 0.365    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -0.0249  |\n",
      "|    value_loss         | 3.04     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 16900    |\n",
      "|    time_elapsed       | 364      |\n",
      "|    total_timesteps    | 84500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.304   |\n",
      "|    explained_variance | -0.0495  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16899    |\n",
      "|    policy_loss        | -0.00473 |\n",
      "|    value_loss         | 3.64     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17000    |\n",
      "|    time_elapsed       | 366      |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16999    |\n",
      "|    policy_loss        | -0.478   |\n",
      "|    value_loss         | 4.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 17100    |\n",
      "|    time_elapsed       | 368      |\n",
      "|    total_timesteps    | 85500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.404   |\n",
      "|    explained_variance | 0.481    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | -0.0738  |\n",
      "|    value_loss         | 2.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 372      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.423   |\n",
      "|    explained_variance | -0.443   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.358   |\n",
      "|    value_loss         | 2.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 86500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.264   |\n",
      "|    explained_variance | 0.499    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | 0.0796   |\n",
      "|    value_loss         | 4.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 376      |\n",
      "|    total_timesteps    | 87000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.773   |\n",
      "|    explained_variance | 0.391    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | 0.142    |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17500    |\n",
      "|    time_elapsed       | 378      |\n",
      "|    total_timesteps    | 87500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.697   |\n",
      "|    explained_variance | 0.757    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17499    |\n",
      "|    policy_loss        | -0.342   |\n",
      "|    value_loss         | 0.255    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 381      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.231   |\n",
      "|    explained_variance | 0.632    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 0.0171   |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 383      |\n",
      "|    total_timesteps    | 88500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.739   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 0.139    |\n",
      "|    value_loss         | 0.244    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 230      |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 89000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.888   |\n",
      "|    explained_variance | 0.828    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | -0.0633  |\n",
      "|    value_loss         | 0.0172   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 387      |\n",
      "|    total_timesteps    | 89500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.455   |\n",
      "|    explained_variance | 0.41     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | 0.94     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 389      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.11    |\n",
      "|    explained_variance | 0.548    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | 0.0437   |\n",
      "|    value_loss         | 2.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18100    |\n",
      "|    time_elapsed       | 391      |\n",
      "|    total_timesteps    | 90500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | -2.86    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18099    |\n",
      "|    policy_loss        | -1.65    |\n",
      "|    value_loss         | 2.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 393      |\n",
      "|    total_timesteps    | 91000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.494   |\n",
      "|    explained_variance | 0.00786  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0.339   |\n",
      "|    value_loss         | 1.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 395      |\n",
      "|    total_timesteps    | 91500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.396   |\n",
      "|    explained_variance | 0.119    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0.396   |\n",
      "|    value_loss         | 0.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18400    |\n",
      "|    time_elapsed       | 397      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.223   |\n",
      "|    explained_variance | 0.535    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18399    |\n",
      "|    policy_loss        | -0.0867  |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 399      |\n",
      "|    total_timesteps    | 92500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.259   |\n",
      "|    explained_variance | 0.619    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | -0.0674  |\n",
      "|    value_loss         | 0.196    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 401      |\n",
      "|    total_timesteps    | 93000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.428   |\n",
      "|    explained_variance | 0.351    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 0.413    |\n",
      "|    value_loss         | 8.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18700    |\n",
      "|    time_elapsed       | 404      |\n",
      "|    total_timesteps    | 93500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0504  |\n",
      "|    explained_variance | 0.197    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18699    |\n",
      "|    policy_loss        | 0.0217   |\n",
      "|    value_loss         | 6.31     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.388   |\n",
      "|    explained_variance | 0.0219   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.0669  |\n",
      "|    value_loss         | 1.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 18900    |\n",
      "|    time_elapsed       | 408      |\n",
      "|    total_timesteps    | 94500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.82    |\n",
      "|    explained_variance | 0.269    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18899    |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    value_loss         | 2.34     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19000    |\n",
      "|    time_elapsed       | 410      |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0.0945   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | 0.544    |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 95500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | 0.399    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -0.198   |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 414      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.843   |\n",
      "|    explained_variance | 0.396    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 0.343    |\n",
      "|    value_loss         | 1.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 416      |\n",
      "|    total_timesteps    | 96500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.183   |\n",
      "|    explained_variance | -0.24    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | 0.086    |\n",
      "|    value_loss         | 3.8      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 418      |\n",
      "|    total_timesteps    | 97000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.247   |\n",
      "|    explained_variance | -0.061   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 0.706    |\n",
      "|    value_loss         | 2.38     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19500    |\n",
      "|    time_elapsed       | 420      |\n",
      "|    total_timesteps    | 97500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.218   |\n",
      "|    explained_variance | 0.374    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19499    |\n",
      "|    policy_loss        | -0.16    |\n",
      "|    value_loss         | 3.32     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 422      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.152   |\n",
      "|    explained_variance | 0.667    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | 0.0197   |\n",
      "|    value_loss         | 0.562    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 424      |\n",
      "|    total_timesteps    | 98500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.289   |\n",
      "|    explained_variance | -0.0183  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0.227   |\n",
      "|    value_loss         | 3.44     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 427      |\n",
      "|    total_timesteps    | 99000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.121   |\n",
      "|    explained_variance | 0.289    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | -0.0635  |\n",
      "|    value_loss         | 2.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 429      |\n",
      "|    total_timesteps    | 99500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.301   |\n",
      "|    explained_variance | 0.257    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | 0.0891   |\n",
      "|    value_loss         | 2.29     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 231      |\n",
      "|    iterations         | 20000    |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.086   |\n",
      "|    explained_variance | -0.0124  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19999    |\n",
      "|    policy_loss        | -0.00421 |\n",
      "|    value_loss         | 1.38     |\n",
      "------------------------------------\n",
      "Evaluation against RandomPlayer:  98 wins out of 100\n",
      "Evaluation against MaxDamagePlayer:  81 wins out of 100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import DummyVecEnv\n",
    "from gymnasium.spaces import Box\n",
    "from poke_env.data import GenData\n",
    "from poke_env.player import Gen9EnvSinglePlayer, RandomPlayer\n",
    "\n",
    "# Define the custom RL player\n",
    "class SimpleRLPlayer(Gen9EnvSinglePlayer):\n",
    "    def embed_battle(self, battle):\n",
    "        \"\"\"\n",
    "        Embeds the current battle state into a vector of 10 values.\n",
    "        \"\"\"\n",
    "        # Initialize base power and damage multipliers\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100  # Rescale base power\n",
    "            )\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=GEN_9_DATA.type_chart,\n",
    "                )\n",
    "\n",
    "        # Count remaining Pokemon for both sides\n",
    "        remaining_mon_team = (\n",
    "            len([mon for mon in battle.team.values() if not mon.fainted]) / 6\n",
    "        )\n",
    "        remaining_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if not mon.fainted]) / 6\n",
    "        )\n",
    "\n",
    "        # Final embedding vector\n",
    "        print(50*\"=\"+\"\\n\",[\n",
    "                moves_base_power,\n",
    "                moves_dmg_multiplier,\n",
    "                [remaining_mon_team, remaining_mon_opponent],\n",
    "            ],\"\\n\"+50*\"=\")\n",
    "        return np.concatenate(\n",
    "            [\n",
    "                moves_base_power,\n",
    "                moves_dmg_multiplier,\n",
    "                [remaining_mon_team, remaining_mon_opponent],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def calc_reward(self, last_state, current_state) -> float:\n",
    "        \"\"\"\n",
    "        Computes the reward for the agent based on the current state.\n",
    "        \"\"\"\n",
    "        return self.reward_computing_helper(\n",
    "            current_state, fainted_value=2, hp_value=1, victory_value=30\n",
    "        )\n",
    "\n",
    "    def describe_embedding(self):\n",
    "        \"\"\"\n",
    "        Describes the observation space for Stable-Baselines3.\n",
    "        \"\"\"\n",
    "        low = [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0]\n",
    "        high = [3, 3, 3, 3, 4, 4, 4, 4, 1, 1]\n",
    "        return Box(\n",
    "            np.array(low, dtype=np.float32),\n",
    "            np.array(high, dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "# Define a MaxDamagePlayer for evaluation\n",
    "class MaxDamagePlayer(RandomPlayer):\n",
    "    def choose_move(self, battle):\n",
    "        # Prioritize moves with the highest base power\n",
    "        if battle.available_moves:\n",
    "            best_move = max(battle.available_moves, key=lambda move: move.base_power)\n",
    "            return self.create_order(best_move)\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n",
    "\n",
    "# Training and evaluation settings\n",
    "NB_TRAINING_STEPS = 100_000\n",
    "TEST_EPISODES = 100\n",
    "GEN_9_DATA = GenData.from_gen(9)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create opponents\n",
    "    random_opponent = RandomPlayer()\n",
    "    max_damage_opponent = MaxDamagePlayer()\n",
    "\n",
    "    # Create training environment\n",
    "    env_player = SimpleRLPlayer(opponent=random_opponent)\n",
    "    env = DummyVecEnv([lambda: env_player])  # Wrap in DummyVecEnv for Stable-Baselines3\n",
    "\n",
    "    # Train the A2C model\n",
    "    model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "    model.learn(total_timesteps=NB_TRAINING_STEPS)\n",
    "    \n",
    "    obs, reward, done, _, info = env_player.step(0)\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _, info = env_player.step(action)\n",
    "\n",
    "    finished_episodes = 0\n",
    "\n",
    "    # Evaluate against RandomPlayer\n",
    "    env_player.reset_battles()\n",
    "    obs, _ = env_player.reset()\n",
    "    finished_episodes = 0\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _, info = env_player.step(action)\n",
    "\n",
    "        if done:\n",
    "            finished_episodes += 1\n",
    "            if finished_episodes >= TEST_EPISODES:\n",
    "                break\n",
    "            obs, _ = env_player.reset()\n",
    "\n",
    "    print(\"Evaluation against RandomPlayer: \", env_player.n_won_battles, \"wins out of\", TEST_EPISODES)\n",
    "\n",
    "    # Evaluate against MaxDamagePlayer\n",
    "    env_player._opponent = max_damage_opponent\n",
    "    env_player.reset_battles()\n",
    "    obs, _ = env_player.reset()\n",
    "    finished_episodes = 0\n",
    "    while True:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, _, info = env_player.step(action)\n",
    "\n",
    "        if done:\n",
    "            finished_episodes += 1\n",
    "            obs, _ = env_player.reset()\n",
    "            if finished_episodes >= TEST_EPISODES:\n",
    "                break\n",
    "\n",
    "    print(\"Evaluation against MaxDamagePlayer: \", env_player.n_won_battles, \"wins out of\", TEST_EPISODES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
